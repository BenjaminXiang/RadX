#version 460 core
#extension GL_GOOGLE_include_directive : enable

#define EXTEND_LOCAL_GROUPS
#include "../include/driver.glsl"
#include "../include/mathlib.glsl"
#include "../include/ballotlib.glsl"

#include "./includes.glsl"

layout (local_size_x = BLOCK_SIZE) in;
shared uint localHistogram[RADICES];

// planned 64-wide for Turing
shared m8pq utype_v _data[Wave_Size];
shared ATYPE addrL[Wave_Size]; //shared uint addrT[Wave_Size];
shared highp uvec4[VEC_SIZE] validAddressL;
shared blocks_info blocks;
#define key _data[Lane_Idx]
#define bcount blocks.count

#ifndef ENABLE_SUBGROUP_PARTITION_SORT
initSubgroupIncFunctionTarget(localHistogram[WHERE], countOffset, 1, uint)
#endif

const uint Wc = RADICES/Wave_Count;
const uint BSIZE = min(Wc,Wave_Size);

// getter by lane_idx
#define addr addrL[Lane_Idx]
#define addrW addr[w]
#define validAddress subgroupInverseBallot(validAddressL[w])

// getter by wave_idx (need additionally multiply and add)
//#define addrWt addrT[Lane_Idx]



// old method
layout ( binding = 0, set = 0, scalar ) readonly subgroupcoherent buffer KeyInU8B { u8vec4 Key8n[]; };
layout ( binding = 2, set = 0, scalar ) readonly buffer RadiceCacheOutB { u8vec4 Key8t[]; };

// 
void main() {
    //const m8pq utype_t Radice_Idx = utype_t(gl_WorkGroupID.y * Wave_Count_RX + w);
    const lowp uint w = Wave_Idx, Wr = Wc * w;

    // clear histogram of block (planned distribute threads)
    [[unroll]] for (lowp uint rk=0u;rk<RADICES;rk+=gl_WorkGroupSize.x) {
        const lowp uint radice = rk + Local_Idx;
        [[flatten]] if (radice < RADICES) localHistogram[radice+0u] = PrefixSum[gl_WorkGroupID.x * RADICES + radice];
    };
    [[flatten]] if (Local_Idx == 0) blocks = get_blocks_info(NumElements), bcount = min(blocks.count, 1048576u);
    LGROUP_BARRIER
    [[flatten]] IFANY (bcount <= 0) return;

    // calculate blocks
    [[flatten]] if (w < VEC_SIZE) { addrW = blocks.offset + Local_Idx; };
    //[[flatten]] if (w < 1u) { addrWt = blocks.wkoffset + Lane_Idx*1u + w; };
    
    [[dependency_infinite]] for ( uint wk = 0; wk < bcount; wk++ ) {
        [[flatten]] if (w < VEC_SIZE) 
            validAddressL[w] = subgroupBallot(lessThan(addrW, blocks.limit));
        
        IFALL(all(not(validAddress))) break;
        
#ifdef READ_U8
        //[[flatten]] if (w < VEC_SIZE) { key[w] = validAddress ? utype_t(Key8n[addrW]) : utype_t(0xFFu); }; // shorter way to get radices (cached)
        [[flatten]] if (w < VEC_SIZE) { key[w] = validAddress ? utype_t(Key8n[addrW][push_block.Shift]) : utype_t(0xFFu); };
#else
        [[flatten]] if (w < VEC_SIZE) { key[w] = utype_t(BFE(validAddress ? Key8n[addrW][push_block.Shift>>1u] : OutOfRange, int((push_block.Shift&1)*BITS_PER_PASS), int(BITS_PER_PASS))); };
#endif

        LGROUP_BARRIER

        // TODO: par_unseq version support 
#ifdef ENABLE_SUBGROUP_PARTITION_SORT
        [[flatten]] if (w == 0u) 
#endif
        [[unroll]] for (lowp uint w=0;w<VEC_SIZE;w++) 
        {
#ifdef ENABLE_SUBGROUP_PARTITION_SORT
            const highp uvec4 blt = subgroupPartitionNV(key[w])&validAddressL[w];
            const uint btc = subgroupPartitionedAddNV(1u,blt), btl = subgroupPartitionedExclusiveAddNV(1u,blt), fLn = subgroupBallotFindMSB(blt);
            uint cntl = 0u; [[flatten]] if (fLn == Lane_Idx && validAddress) { cntl = add(localHistogram[uint(key[w])], btc); };
            {
                const uint offset = subgroupShuffle(cntl,fLn) + btl;
                [[flatten]] if (validAddress) { ValueTmp[offset] = ValueIn[addrW], KeyTmp[offset] = KeyIn[addrW]; };
            };
#else
#ifdef SIMPLER_SORT
            [[flatten]] if (key[w] == Wr && validAddress) {
                const uint offset = countOffset(key[w]);
                ValueTmp[offset] = ValueIn[addrW], KeyTmp[offset] = KeyIn[addrW];
            };
#else
            bool found = !validAddress || keyW<Wr || keyW>=(Wr+Wc);
             for (lowp uint t=0;t<BSIZE;t+=1u) {
                [[flatten]] if (!found && (found = subgroupMin(key[w])==key[w])) {
                    const uint offset = countOffset(keyW);
                    ValueTmp[offset] = ValueIn[addrW], KeyTmp[offset] = KeyIn[addrW];
                };
                [[flatten]] if ( subgroupAll(found) ) { break; };
            };
#endif
#endif
        };

        LGROUP_BARRIER
            [[flatten]] if (w < VEC_SIZE) { addrW += ( Wave_Size_RT << VEC_SHIF ); };
            //[[flatten]] if (w < 1u) { addrWt += Wave_Size_RT; };
    };
};
