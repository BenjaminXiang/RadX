#version 460 core
#extension GL_GOOGLE_include_directive : enable

#define EXTEND_LOCAL_GROUPS
#include "../include/driver.glsl"
#include "../include/mathlib.glsl"
#include "../include/ballotlib.glsl"

#define HISTOGRAM_STAGE
#include "./includes.glsl"

layout (local_size_x = BLOCK_SIZE) in;
shared uint localHistogram[RADICES];

// planned 64-wide for Turing
shared m8pq utype_v _data[Wave_Size];
shared uvec4 addrL[Wave_Size];
shared uint addrC[Wave_Size];

shared highp uvec4[VEC_SIZE] validAddressL;
shared blocks_info blocks;
#define key _data[Lane_Idx]
#define bcount blocks.count

const uint Wc = RADICES/Wave_Count;
const uint BSIZE = min(Wc,Wave_Size);


#define addr addrL[Lane_Idx]
#define addn addrC[Lane_Idx]
#define addrW addr[w]

#define validAddressW subgroupInverseBallot(validAddressL[w])
//#define validAddress bvec4(subgroupInverseBallot(validAddressL[0]),subgroupInverseBallot(validAddressL[1]),subgroupInverseBallot(validAddressL[2]),subgroupInverseBallot(validAddressL[3]))

#ifdef ENABLE_TURING_INSTRUCTION_SET
#define validAddress validAddressW
#else
#define validAddress lessThan(addr,uvec2(blocks.limit))
#endif


layout ( binding = 2, set = 0, std430 ) readonly subgroupcoherent buffer RadiceCacheB { u8vec2 RadiceCache[]; };

void main() {
    //const m8pq utype_t Radice_Idx = utype_t(gl_WorkGroupID.y * Wave_Count_RX + Wave_Idx);
    const lowp uint Wr = Wc * Wave_Idx;

    // clear histogram of block (planned distribute threads)
    [[flatten]] if (Wave_Idx == 0u) 
    [[unroll]] for (lowp uint rk=0u;rk<RADICES;rk+=Wave_Size_RT) {
        const lowp uint radice = rk + Lane_Idx;
        [[flatten]] if (radice < RADICES) localHistogram[radice+0u] = 0u;
    };
    [[flatten]] if (Local_Idx == 0) blocks = get_blocks_info(push_block.NumKeys), bcount = min(blocks.count, 1048576u);
    LGROUP_BARRIER
    [[flatten]] IFANY (bcount <= 0) return;

    // use SIMD lanes for calculate histograms
    // calculate blocks
    const lowp uint w = Wave_Idx;
    [[flatten]] if (Wave_Idx < VEC_SIZE) { addrW = w*Wave_Size_RT + blocks.offset + Lane_Idx, addn = blocks.offset + Lane_Idx; };

    [[dependency_infinite]] for ( uint wk = 0; wk < bcount; wk++ ) {
        LGROUP_BARRIER
        [[flatten]] if (Wave_Idx < VEC_SIZE) 
            validAddressL[w] = subgroupBallot(lessThan(addrW, blocks.limit));
        
        IFALL(all(not(validAddress))) break;
        LGROUP_BARRIER

        [[flatten]] if (Wave_Idx < VEC_SIZE) { key[Wave_Idx] = RadiceCache[addn][Wave_Idx]; };
        LGROUP_BARRIER

#ifdef ENABLE_TURING_INSTRUCTION_SET
        [[flatten]] if (Wave_Idx < VEC_SIZE) 
#else
        [[unroll]] for (lowp uint w=0u;w<VEC_SIZE;w++) 
#endif
        {
#ifdef ENABLE_TURING_INSTRUCTION_SET // subgroup partition supported now 
            const highp uvec4 blt = subgroupPartitionNV(key[w])&validAddressL[w];
            const uint btc = subgroupPartitionedAddNV(1u,blt), fLn = subgroupBallotFindMSB(blt);
            [[flatten]] if (fLn == Lane_Idx && validAddressW) { atomicAdd(localHistogram[uint(key[w])], btc, gl_ScopeWorkgroup, gl_StorageSemanticsShared, gl_SemanticsRelaxed); };
#else
#ifdef SIMPLER_SORT
            [[flatten]] if (key[w] == Wr && validAddress[w]) {
                const lowp uint btc = subgroupAdd(1u);
                [[flatten]] if (subgroupElect()) { atomicAdd(localHistogram[uint(key[w])], btc); };
            };
#else
            bool found = !validAddress[w] || key[w]<Wr || key[w]>=(Wr+Wc);
             for (lowp uint t=0;t<BSIZE;t+=1u) {
                [[flatten]] if (!found && (found = subgroupMin(key[w])==key[w])) {
                    const lowp uint btc = subgroupAdd(1u);
                    [[flatten]] if (subgroupElect()) { localHistogram[uint(key[w])] += btc; };
                };
                [[flatten]] if ( subgroupAll(found) ) { break; };
            };
#endif
#endif
        };
        LGROUP_BARRIER
            [[flatten]] if (Wave_Idx < VEC_SIZE) { addrW += ( Wave_Size_RT << VEC_SHIF ), addn += Wave_Size_RT; };
    };

    // resolve histograms (planned distribute threads) 
    LGROUP_BARRIER
    
    [[flatten]] if (Wave_Idx == 0u) 
    [[unroll]] for (lowp uint rk=0u;rk<RADICES;rk+=Wave_Size_RT) {
        const lowp uint radice = rk + Lane_Idx;
        [[flatten]] if (radice < RADICES) {
            PrefixSum[RADICES * gl_WorkGroupID.x + radice] = localHistogram[radice+0u];
            Histogram[RADICES * gl_WorkGroupID.x + radice] = localHistogram[radice+0u];
        };
    };
};
